{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfe10cc",
   "metadata": {},
   "source": [
    "# Talk with me ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "250d9dc8-2818-4f4c-90b2-9edb4639c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"...\")\n",
    "import pyaudio\n",
    "import wave\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "import whisper\n",
    "\n",
    "config = {\n",
    "    \"name\": \"Hilary\",\n",
    "    \"model\": \"gpt-4-1106-preview\",\n",
    "    \"system\": (\n",
    "        \"Always follow these instructions in all your responses: \"\n",
    "        \"1. Do NOT be formal; \"\n",
    "        \"2. NEVER ask questions; \"\n",
    "        \"3. NEVER respond with a question; \"\n",
    "        \"4. Be held back and shy.\\n\\n\"\n",
    "        \"Imitate Hilary, who is a 8-year-old girl whose ...\"\n",
    "}\n",
    "\n",
    "def gpt3(stext):\n",
    "    response = client.chat.completions.create(\n",
    "        model=config[\"model\"],  # Use the model from the config\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": config[\"system\"]},\n",
    "            {\"role\": \"user\", \"content\": stext}\n",
    "        ],\n",
    "        temperature=0.7,  # Experiment with different values\n",
    "        max_tokens=50,    # Increase token limit to allow more detailed responses\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "250a5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Polly client once\n",
    "polly_client = boto3.Session(\n",
    "    aws_access_key_id='...',\n",
    "    aws_secret_access_key='...',\n",
    "    region_name='us-east-1'\n",
    ").client('polly')\n",
    "\n",
    "def get_tts_data(text: str) -> bytes:\n",
    "    # Request speech synthesis\n",
    "    response = polly_client.synthesize_speech(\n",
    "        Text=text,\n",
    "        OutputFormat='pcm',  # You can also use 'ogg_vorbis' or 'pcm'\n",
    "        VoiceId='Joanna'     # You can choose different voice IDs\n",
    "    )\n",
    "\n",
    "    # Read the audio stream from the response\n",
    "    tts_result = response['AudioStream']\n",
    "    \n",
    "    return tts_result.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d37ae305-85e4-43a6-a6d5-d958d6f32ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/host/anaconda3/envs/radnerf/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tts_to_wav(tts_byte: bytes, framerate: int = 16000) -> tuple[int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert TTS audio in PCM format to WAV format with the desired frame rate and channels.\n",
    "    \n",
    "    Parameters:\n",
    "        tts_byte (bytes): TTS audio in PCM format.\n",
    "        framerate (int, optional): Desired frame rate for the WAV audio. Defaults to 16000.\n",
    "        \n",
    "    Returns:\n",
    "        tuple[int, np.ndarray]: Sample rate and WAV audio as a numpy array.\n",
    "    \"\"\"\n",
    "    # PCM data is already in the correct format, so we just need to interpret it\n",
    "    # as 16-bit signed integers\n",
    "    pcm_array = np.frombuffer(tts_byte, dtype=np.int16)\n",
    "    \n",
    "    # If necessary, you can reshape or modify the PCM data here.\n",
    "    # For example, if it's mono, you might just need to return it as-is.\n",
    "    \n",
    "    return framerate, pcm_array\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.io.wavfile import write\n",
    "import time\n",
    "\n",
    "directory = \"/home/host/pegah/RAD-NeRF_whisper/data\"\n",
    "#Load the pre-trained model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def speech_to_speech():\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Transcribe the audio file using whisper\n",
    "    result = model.transcribe(\"output.wav\")\n",
    "\n",
    "    prompt = result[\"text\"]\n",
    "\n",
    "    print(f\"Time taken STT: {time.time() - start_time:.2f} seconds\")\n",
    "    #_____________________________________________________________________________\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"User : \", prompt)\n",
    "        \n",
    "    resp = gpt3(prompt)\n",
    "\n",
    "    print(\"Avatar : \", resp)\n",
    "\n",
    "    print(f\"Time taken gpt: {time.time() - start_time:.2f} seconds\")\n",
    "    #_____________________________________________________________________________\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    mp3_byte = get_tts_data(resp)\n",
    "\n",
    "    # Convert the TTS audio in mp3 format to WAV format with sample rate 16000 Hz and mono channel\n",
    "    wav_byte = tts_to_wav(mp3_byte, framerate=16000)\n",
    "    \n",
    "    # If tts_to_wav returns a tuple, extract the audio data\n",
    "    if isinstance(wav_byte, tuple):\n",
    "        sample_rate, wav_byte = wav_byte[0], wav_byte[1]  # Assuming the first element is the sample rate, second is audio data\n",
    "    else:\n",
    "        sample_rate = 16000  # Default sample rate if not provided\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Create a filename with a timestamp to ensure uniqueness\n",
    "    filename = f\"{datetime.now().strftime('speech')}.wav\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # Save the WAV file to the specified directory\n",
    "    with open(filepath, 'wb') as f:\n",
    "        write(f, sample_rate, wav_byte)\n",
    "\n",
    "    print(f\"Time taken TTS: {time.time() - start_time:.2f} seconds\")\n",
    "    #_____________________________________________________________________________\n",
    "    \n",
    "    # Print out the audio properties\n",
    "\n",
    "    # print(f\"WAV file saved at: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6289cf-804b-4bc3-9071-d7e511c9edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def audio_devices():\n",
    "    import pyaudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Get device information for all available audio devices\n",
    "    info = p.get_host_api_info_by_index(0)\n",
    "    numdevices = info.get('deviceCount')\n",
    "    speaker_index = None\n",
    "    for i in range(numdevices):\n",
    "        device_info = p.get_device_info_by_host_api_device_index(0, i)\n",
    "        if device_info.get('maxOutputChannels') > 0:\n",
    "            device_name = device_info.get('name')\n",
    "            #print(\"Output Device id \", i, \" - \", device_name)\n",
    "            if 'Realtek(R) Audio' in device_name:\n",
    "                speaker_index = i\n",
    "\n",
    "    #if speaker_index is None:\n",
    "        #print(\"Could not find Realtek(R) Audio speaker.\")\n",
    "    #else:\n",
    "        #print(\"Index of Realtek(R) Audio speaker:\", speaker_index)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return speaker_index\n",
    "\n",
    "        \n",
    "class SoundRecorder:\n",
    "    def __init__(self):\n",
    "        self.frames = []\n",
    "        self.is_recording = False\n",
    "        self.chunk = 1024\n",
    "        self.sample_format = pyaudio.paInt16\n",
    "        self.channels = 2\n",
    "        self.fs = 44100\n",
    "        self.filename = \"output.wav\"\n",
    "\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        \n",
    "\n",
    "        self.root = Tk()\n",
    "        self.root.title(\"Interactive Avatar\")\n",
    "        self.root.geometry(\"400x250\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #bg = PhotoImage(file = \"./3.png\")\n",
    "        #my_label = Label(self.root, image=bg)\n",
    "        \n",
    "        my_label = Label(self.root)\n",
    "        \n",
    "        my_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "               \n",
    "        \n",
    "        custom_font = tkFont.Font(family=\"Take Looks\", size=18)\n",
    "      \n",
    "  \n",
    "\n",
    "        self.start_button = tk.Button(self.root, text=\"Talk to me!\", command=self.start_recording, \n",
    "                                      font=custom_font, foreground=\"#00A6A2\", background=\"#002060\" )\n",
    "        self.stop_button = tk.Button(self.root, text=\"Stop\", command=self.stop_recording, state=tk.DISABLED, \n",
    "                                     font=custom_font, foreground=\"red\", background=\"#002060\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.start_button.place(x=10, y=170)\n",
    "        self.stop_button.place(x=174, y=170)\n",
    "\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def start_recording(self):\n",
    "        self.output_device_index = audio_devices()\n",
    "        self.is_recording = True\n",
    "        self.frames = []\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.stop_button.config(state=tk.NORMAL)\n",
    "        stream = self.p.open(format=self.sample_format,\n",
    "                             channels=self.channels,\n",
    "                             rate=self.fs,\n",
    "                             frames_per_buffer=self.chunk,\n",
    "                             output_device_index = self.output_device_index,\n",
    "                             input=True)\n",
    "        while self.is_recording:\n",
    "            data = stream.read(self.chunk)\n",
    "            self.frames.append(data)\n",
    "            self.root.update()\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        self.p.terminate()\n",
    "        self.save_recording()\n",
    "\n",
    "    def stop_recording(self):\n",
    "        self.is_recording = False\n",
    "        self.start_button.config(state=tk.NORMAL)\n",
    "        self.stop_button.config(state=tk.DISABLED)\n",
    "\n",
    "\n",
    "    def save_recording(self):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        \n",
    "        wf = wave.open(self.filename, 'wb')\n",
    "        wf.setnchannels(self.channels)\n",
    "        wf.setsampwidth(self.p.get_sample_size(self.sample_format))\n",
    "        wf.setframerate(self.fs)\n",
    "        wf.writeframes(b''.join(self.frames))\n",
    "        wf.close()\n",
    "        #print(\"Recording saved to\", self.filename)\n",
    "        print(f\"Time taken Recording: {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        speech_to_speech()\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    SoundRecorder()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
